{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchを使ってLSTMで文章分類を実装してみた\n",
    "\n",
    "https://qiita.com/m__k/items/841950a57a0d7ff05506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import linecache\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dokujo-tsushin', 'it-life-hack', 'kaden-channel', 'livedoor-homme', 'movie-enter', 'peachy', 'smax', 'sports-watch', 'topic-news']\n"
     ]
    }
   ],
   "source": [
    "# カテゴリを配列で取得\n",
    "categories = [name for name in os.listdir(\"text\") if os.path.isdir(\"text/\" + name)]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: $<class 'pandas.core.frame.DataFrame'>\n",
      "shape: $(0, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, category]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = pd.DataFrame(columns=[\"title\", \"category\"])\n",
    "print(f\"type: ${type(datasets)}\")\n",
    "print(f\"shape: ${datasets.shape}\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: $<class 'pandas.core.frame.DataFrame'>\n",
      "shape: $(7376, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>友人代表のスピーチ、独女はどうこなしている？\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ネットで断ち切れない元カレとの縁\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ムダな抵抗！？ 加齢の現実\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>税金を払うのは私たちなんですけど！\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>爆笑問題・田中裕二も驚く「ひるおび!」での恵俊彰の“天然”ぶり\\n</td>\n",
       "      <td>topic-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>黒田勇樹のDV騒動 ネット掲示板では冷ややかな声も\\n</td>\n",
       "      <td>topic-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373</th>\n",
       "      <td>サムスンのアンドロイド搭載カメラが韓国で話題に\\n</td>\n",
       "      <td>topic-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>米紙も注目したゲーム「竹島争奪戦」\\n</td>\n",
       "      <td>topic-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7375</th>\n",
       "      <td>ジャンプ連載漫画が終了に、ユーザが新たな提案!?\\n</td>\n",
       "      <td>topic-news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7376 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title        category\n",
       "0               友人代表のスピーチ、独女はどうこなしている？\\n  dokujo-tsushin\n",
       "1                     ネットで断ち切れない元カレとの縁\\n  dokujo-tsushin\n",
       "2          相次ぐ芸能人の“すっぴん”披露　その時、独女の心境は？\\n  dokujo-tsushin\n",
       "3                        ムダな抵抗！？ 加齢の現実\\n  dokujo-tsushin\n",
       "4                    税金を払うのは私たちなんですけど！\\n  dokujo-tsushin\n",
       "...                                  ...             ...\n",
       "7371   爆笑問題・田中裕二も驚く「ひるおび!」での恵俊彰の“天然”ぶり\\n      topic-news\n",
       "7372         黒田勇樹のDV騒動 ネット掲示板では冷ややかな声も\\n      topic-news\n",
       "7373           サムスンのアンドロイド搭載カメラが韓国で話題に\\n      topic-news\n",
       "7374                 米紙も注目したゲーム「竹島争奪戦」\\n      topic-news\n",
       "7375          ジャンプ連載漫画が終了に、ユーザが新たな提案!?\\n      topic-news\n",
       "\n",
       "[7376 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat in categories:\n",
    "    path = \"text/\" + cat + \"/*.txt\"\n",
    "    files = glob(path)\n",
    "    for text_name in files:\n",
    "        title = linecache.getline(text_name, 3)\n",
    "        s = pd.Series([title, cat], index=datasets.columns)\n",
    "        datasets = datasets.append(s, ignore_index=True)\n",
    "\n",
    "print(f\"type: ${type(datasets)}\")\n",
    "print(f\"shape: ${datasets.shape}\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>私たち、姪＆甥がかわいくて仕方ないんです！\\n</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>逮捕されたソフトバンク・堂上隼人に非難が殺到\\n</td>\n",
       "      <td>topic-news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>【オトナ女子映画部】アラサーアイドルがヒーローに！安っぽさやくだらなさを楽しむ『エイトレンジ...</td>\n",
       "      <td>dokujo-tsushin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPhoneユーザー歓喜！？コンビニ無線LAN「LAWSON Wi-Fi」がiPhoneに対応\\n</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ワイヤレス・テクノジー・パーク2012：日本無線ブースにてスマートフォンをITS受信機にする...</td>\n",
       "      <td>smax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        category\n",
       "0                            私たち、姪＆甥がかわいくて仕方ないんです！\\n  dokujo-tsushin\n",
       "1                           逮捕されたソフトバンク・堂上隼人に非難が殺到\\n      topic-news\n",
       "2  【オトナ女子映画部】アラサーアイドルがヒーローに！安っぽさやくだらなさを楽しむ『エイトレンジ...  dokujo-tsushin\n",
       "3  iPhoneユーザー歓喜！？コンビニ無線LAN「LAWSON Wi-Fi」がiPhoneに対応\\n            smax\n",
       "4  ワイヤレス・テクノジー・パーク2012：日本無線ブースにてスマートフォンをITS受信機にする...            smax"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データフレームシャッフル\n",
    "datasets = datasets.sample(frac=1).reset_index(drop=True)\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchでLSTMをする際、食わせるインプットデータは３次元のテンソルある必要があります。具体的には、文章の長さ × バッチサイズ × ベクトル次元数 となっています。今回のインプットデータは文章（livedoorニュースのタイトル文）であり、この文章を3次元テンソルに変換する必要があります。\n",
    "\n",
    "バッチサイズは一旦無視して、ひとまず文章を以下のように２次元のマトリクスに変換することを考えます。\n",
    "\n",
    "```\n",
    "人口知能は人間の仕事を奪った\n",
    "（形態素解析）→['人口','知能','は','人間','の','仕事','を','奪っ','た']\n",
    "(各単語をベクトルで置換)→[[0.2 0.5 -0.9 1.3 ...], # 「人口」の単語ベクトル\n",
    "                     [1.3 0.1 2.9 -1.3 ...], # 「知能」の単語ベクトル\n",
    "                      ...\n",
    "                     [0.9 -0.3 -0.1 3.0 ...] # 「た」の単語ベクトル\n",
    "                    ]\n",
    "```\n",
    "単語のベクトルは例えばWord2Vecで学習済みのものがあればそれを使う方が精度が良いらしいですが、一旦はPyTorchの torch.nn.Embedding を使いましょう。こいつの詳細はPyTorchのチュートリアルに任せますが、要はランダムな単語ベクトル群を生成してくれるやつです。実際に使ってみると分かりやすいです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n",
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.set_printoptions(linewidth=1000)\n",
    "\n",
    "import torch.nn as nn\n",
    "import MeCab\n",
    "import re\n",
    "\n",
    "# 実行する前に下記を実行すること\n",
    "# cp -p /etc/mecabrc /usr//local/etc/\n",
    "\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下の宣言で行が単語ベクトル、列が単語のインデックスのマトリクスを生成してる感じ\n",
    "embeds = nn.Embedding(10, 6) # (Embedding(単語の合計数（1つの文を構成する単語数）, ベクトル次元数))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: $<class 'torch.nn.modules.sparse.Embedding'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"type: ${type(embeds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4335, -0.0524,  0.2694,  0.9246, -0.2736, -0.0444]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# ３行目の要素を取り出したいならば\n",
    "w1 = torch.tensor([2])\n",
    "print(embeds(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4335, -0.0524,  0.2694,  0.9246, -0.2736, -0.0444],\n",
      "        [ 0.3472, -1.1720, -0.9931,  0.2534,  0.5588,  1.7256],\n",
      "        [-0.0286,  0.3725,  0.6421,  2.6326,  1.1246, -1.1369]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 3行目、5行目、１０行目の要素を取り出したいならば、\n",
    "w2 = torch.tensor([2,4,9])\n",
    "print(embeds(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.Embeddingを使えば文章を簡単に２次元のマトリクスにすることができます。そのために、文章を単語IDの系列データとして変換すれば、さくっと文章を２次元のマトリクスにできそうです。文章を形態素解析して、全ての単語にIDを割り振って、文章を単語IDの系列データにする前の一連の流れは、例えば以下のような感じでよいでしょう。\n",
    "（形態素解析にはとりえあずMeCab使います。前処理で英数字や記号は諸々削除していますが、実際は要件に応じて相談。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wakati(sentence):\n",
    "    # MeCabで分かち書き\n",
    "    sentence = tagger.parse(sentence)\n",
    "    # 半角全角英数字除去\n",
    "    sentence = re.sub(r'[0-9０-９a-zA-Zａ-ｚＡ-Ｚ]+', \" \", sentence)\n",
    "    # 記号もろもろ除去\n",
    "    sentence = re.sub(r'[\\．_－―─！＠＃＄％＾＆\\-‐|\\\\＊\\“（）＿■×+α※÷⇒—●★☆〇◎◆▼◇△□(：〜～＋=)／*&^%$#@!~`){}［］…\\[\\]\\\"\\'\\”\\’:;<>?＜＞〔〕〈〉？、。・,\\./『』【】「」→←○《》≪≫\\n\\u3000]+', \"\", sentence)\n",
    "    # スペースで区切って形態素の配列へ\n",
    "    wakati = sentence.split(\" \")\n",
    "    # 空の要素は削除\n",
    "    wakati = list(filter((\"\").__ne__, wakati))\n",
    "    return wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人工', '知能', 'は', '人間', 'の', '仕事', 'を', '奪っ', 'た']\n"
     ]
    }
   ],
   "source": [
    "# テスト\n",
    "test = \"【人工知能】は「人間」の仕事を奪った\"\n",
    "print(make_wakati(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size :  13276\n"
     ]
    }
   ],
   "source": [
    "# 単語ID辞書を作成する\n",
    "word2index = {}\n",
    "for title in datasets[\"title\"]:\n",
    "    wakati = make_wakati(title)\n",
    "    for word in wakati:\n",
    "        if word in word2index: continue\n",
    "        word2index[word] = len(word2index)\n",
    "print(\"vocab size : \", len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8103,   64, 1047,  997,  134, 1602,  273, 1603,   64, 8144, 7069,  140, 8538])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 文章を単語IDの系列データに変換\n",
    "# PyTorchのLSTMのインプットになるデータなので、もちろんtensor型で\n",
    "def sentence2index(sentence):\n",
    "    wakati = make_wakati(sentence)\n",
    "    return torch.tensor([word2index[w] for w in wakati], dtype=torch.long)\n",
    "\n",
    "# テスト\n",
    "test = \"例のあのメニューも！ニコニコ超会議のフードコートメニュー14種類紹介（前半）\"\n",
    "test_result = sentence2index(test)\n",
    "print(test_result)\n",
    "print(type(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13276"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 単語のベクトル数\n",
    "EMBEDDING_DIM = 10\n",
    "# 全単語数を取得\n",
    "VOCAB_SIZE = len(word2index)\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([9799,   64,  176,   18, 9800,   14,  519,   84,   64, 1381, 4248,   30, 6434])\n"
     ]
    }
   ],
   "source": [
    "test = \"ユージの前に立ちはだかったJOY「僕はAKBの高橋みなみを守る」\"\n",
    "# 単語IDの系列データに変換\n",
    "inputs = sentence2index(test)\n",
    "\n",
    "print(type(inputs))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.sparse.Embedding'>\n",
      "Embedding(13276, 10)\n"
     ]
    }
   ],
   "source": [
    "# 各単語のベクトルをまとめて取得\n",
    "# 以下の宣言で行が単語ベクトル、列が単語のインデックスのマトリクスを生成してる感じ\n",
    "# (Embedding(単語の合計数（1つの文を構成する単語数）, ベクトル次元数))\n",
    "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "\n",
    "print(type(embeds))\n",
    "print(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([13, 10])\n",
      "tensor([[ 8.5704e-01, -1.1438e+00,  6.4939e-01, -1.0367e-01,  1.3721e+00, -4.1872e-01,  2.4071e+00, -1.3405e+00,  3.6437e-02,  1.6093e-01],\n",
      "        [ 1.7554e-01,  2.9242e-01, -8.7265e-01, -5.2237e-02,  5.0813e-01,  2.0564e+00,  1.2138e-01, -1.8944e+00,  1.0731e-01, -4.3561e-01],\n",
      "        [-2.8149e-02, -5.9173e-01, -4.0962e-01, -1.9348e+00,  3.1610e-01,  1.3705e+00, -1.8305e+00, -5.3600e-01, -1.5486e-01, -6.1525e-02],\n",
      "        [ 4.8530e-01, -5.8736e-01,  4.9884e-01, -3.7233e-01,  6.3638e-01, -4.0580e-01, -2.5622e-01,  2.1412e+00, -4.9334e-01,  1.3339e+00],\n",
      "        [ 5.0238e-02, -1.4846e+00,  1.9270e+00, -3.6990e-01, -5.7551e-01,  1.2508e+00, -9.2561e-01,  1.8859e-01, -2.9269e-01, -9.0330e-01],\n",
      "        [-4.9547e-01, -5.1980e-01, -1.4891e+00,  6.4522e-01,  1.0830e+00, -1.6218e-01,  6.0020e-01, -2.4458e+00,  1.0878e+00,  1.2651e+00],\n",
      "        [-1.3956e+00, -1.4083e+00,  3.3482e-01, -7.1853e-02,  9.3753e-01,  4.6177e-04,  6.3564e-01,  1.0854e+00,  3.6666e-01, -2.3314e-01],\n",
      "        [-8.4194e-01, -2.2240e-01, -1.0458e+00,  9.6673e-01,  3.3141e-01, -1.8832e-01, -1.2049e+00,  1.1090e+00, -6.9757e-01, -1.2094e+00],\n",
      "        [ 1.7554e-01,  2.9242e-01, -8.7265e-01, -5.2237e-02,  5.0813e-01,  2.0564e+00,  1.2138e-01, -1.8944e+00,  1.0731e-01, -4.3561e-01],\n",
      "        [-1.8180e-01,  7.1836e-01, -8.9643e-01,  3.2611e+00,  2.2977e+00, -1.9086e+00,  8.0181e-02,  1.3615e+00, -4.0599e-02, -2.1626e-01],\n",
      "        [ 6.4938e-02, -1.2179e+00, -7.2409e-02, -1.0706e+00, -1.2376e-01, -1.5741e-01, -1.2034e+00,  5.6046e-01, -4.7009e-01,  8.9361e-01],\n",
      "        [ 3.4501e-01, -7.9660e-02,  7.8975e-02,  1.3462e+00, -1.2956e+00,  5.7701e-01, -1.8239e-01,  8.3430e-02, -3.1998e-01,  1.1998e+00],\n",
      "        [ 1.4425e+00, -1.6154e+00,  9.8874e-01,  4.4956e-01,  4.9313e-01, -3.7394e-01,  1.8295e+00,  9.6924e-01, -2.4346e-01,  1.2059e-02]], grad_fn=<EmbeddingBackward>)\n",
      "###################テスト終わり#####################\n"
     ]
    }
   ],
   "source": [
    "sentence_matrix = embeds(inputs)\n",
    "print(type(sentence_matrix))\n",
    "print(sentence_matrix.size())\n",
    "print(sentence_matrix)\n",
    "print(\"###################テスト終わり#####################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['震災', 'を', 'うけ', 'て', '感じ', 'た', '大切', 'だ', 'と', '思っ', 'た', 'こと']\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(word2index)\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_DIM = 128\n",
    "embeds = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "s1 = \"震災をうけて感じた、大切だと思ったこと\"\n",
    "print(make_wakati(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1.size():$torch.Size([12, 1, 128])\n",
      "tensor([[[ 0.0061,  0.0085, -0.0231,  ..., -0.0142,  0.0287,  0.0123]],\n",
      "\n",
      "        [[ 0.0234, -0.0810, -0.0107,  ..., -0.0354,  0.0503,  0.0090]],\n",
      "\n",
      "        [[ 0.0766, -0.0149,  0.0247,  ...,  0.0161,  0.0862,  0.0104]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0695, -0.0210,  0.0856,  ...,  0.0198,  0.0383,  0.0714]],\n",
      "\n",
      "        [[-0.0503,  0.0199,  0.0963,  ...,  0.0219,  0.0594,  0.0575]],\n",
      "\n",
      "        [[-0.0248, -0.0254,  0.1292,  ...,  0.0692,  0.0794,  0.0824]]], grad_fn=<StackBackward>)\n",
      "out2[0].size():$torch.Size([1, 1, 128])\n",
      "out2[1].size():$torch.Size([1, 1, 128])\n",
      "(tensor([[[-0.0248, -0.0254,  0.1292, -0.0355,  0.0104, -0.0645,  0.0366,  0.0763, -0.0858,  0.0273,  0.0443,  0.0019, -0.0011,  0.0123, -0.0121, -0.0128, -0.0241, -0.0420, -0.1082, -0.0537,  0.0611, -0.0095,  0.0192,  0.0554,  0.0166,  0.0227, -0.0064, -0.0253, -0.0063, -0.0208,  0.0339,  0.0085,  0.0835,  0.0932,  0.0089,  0.0070, -0.0098, -0.0683,  0.0022, -0.0649,  0.1160,  0.0326,  0.0378,  0.0999, -0.0503,  0.1565,  0.0925, -0.0998,  0.0077, -0.0197,  0.0907, -0.1153,  0.0737, -0.0554, -0.0235,  0.0805,  0.0440, -0.1177,  0.0064, -0.0695,  0.0419,  0.0089, -0.0064, -0.0541,  0.0876,  0.0031, -0.1285, -0.0661, -0.1004, -0.0402, -0.0507, -0.0229, -0.0803, -0.0500,  0.0484,  0.0956,  0.0240,  0.0557,  0.0409, -0.0005, -0.0515, -0.0464, -0.0882,  0.0502, -0.0692,  0.0719,  0.0423, -0.0931, -0.0399, -0.0552, -0.1029, -0.0459,  0.0723,  0.0504, -0.0073,  0.0152,  0.0642, -0.0192, -0.0487,  0.0212,  0.0145, -0.0036, -0.0368, -0.0988, -0.1498, -0.0280,  0.0091,  0.0675,  0.0305, -0.0414,\n",
      "          -0.0283, -0.0547, -0.0934,  0.1334,  0.0436,  0.0036, -0.0054,  0.0161, -0.0848,  0.0515, -0.0673,  0.0007, -0.0153, -0.0420, -0.0738,  0.0692,  0.0794,  0.0824]]], grad_fn=<StackBackward>), tensor([[[-0.0552, -0.0497,  0.2489, -0.0731,  0.0180, -0.1343,  0.0721,  0.1454, -0.1595,  0.0635,  0.0865,  0.0039, -0.0022,  0.0263, -0.0236, -0.0244, -0.0439, -0.0983, -0.2132, -0.1133,  0.1295, -0.0186,  0.0365,  0.1201,  0.0309,  0.0458, -0.0122, -0.0507, -0.0122, -0.0517,  0.0662,  0.0174,  0.1500,  0.1909,  0.0164,  0.0127, -0.0194, -0.1462,  0.0044, -0.1335,  0.2251,  0.0769,  0.0706,  0.2009, -0.0932,  0.3193,  0.1791, -0.1950,  0.0163, -0.0394,  0.1740, -0.2162,  0.1379, -0.1288, -0.0578,  0.1677,  0.0939, -0.2474,  0.0120, -0.1442,  0.0913,  0.0176, -0.0121, -0.1054,  0.2013,  0.0062, -0.2624, -0.1624, -0.1741, -0.0855, -0.1070, -0.0504, -0.1909, -0.0882,  0.0956,  0.1633,  0.0521,  0.1057,  0.0781, -0.0009, -0.1151, -0.0872, -0.2106,  0.1009, -0.1397,  0.1553,  0.0862, -0.1822, -0.0861, -0.1114, -0.2144, -0.0825,  0.1466,  0.1031, -0.0126,  0.0333,  0.1279, -0.0386, -0.0960,  0.0430,  0.0312, -0.0077, -0.0702, -0.2152, -0.3361, -0.0613,  0.0170,  0.1341,  0.0538, -0.0792,\n",
      "          -0.0545, -0.1026, -0.2021,  0.2412,  0.0799,  0.0069, -0.0105,  0.0335, -0.1651,  0.0915, -0.1225,  0.0013, -0.0291, -0.0774, -0.1308,  0.1254,  0.1433,  0.1440]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "inputs1 = sentence2index(s1)\n",
    "emb1 = embeds(inputs1)\n",
    "lstm_inputs1 = emb1.view(len(inputs1), 1, -1)\n",
    "lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM)\n",
    "out1, out2 = lstm(lstm_inputs1)\n",
    "print(f\"out1.size():${out1.size()}\")\n",
    "print(out1)\n",
    "print(f\"out2[0].size():${out2[0].size()}\")\n",
    "print(f\"out2[1].size():${out2[1].size()}\")\n",
    "print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch_lstm)",
   "language": "python",
   "name": "pytorch_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
