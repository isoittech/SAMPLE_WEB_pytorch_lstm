{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "\n",
    "PyTorchを使ってLSTMで文章分類を実装してみた。    \n",
    "前回のSeq2Seqの実装に引き続き、今回はSeq2SeqにAttentionを加えたAttention Seq2SeqをPyTorchで実装してみました。  \n",
    "\n",
    "自分みたいな初学者でもわかりやすくPyTorchでAttentionを実装しているソースコードがあまり見つからず、PyTorchのAttentionのチュートリアルもあるにはあるのですが、ミニバッチ学習してない(?)っぽいし、このタスク用にあれこれカスタマイズされてそうな感じでもっとシンプルにプレーン(?)なAttentionの実装をしてみたかった、ということで自分でAttentionを実装してみました。  \n",
    "Attentionの実装に手こずっている人に少しでもご参考になる情報をお届けできれば幸いです。  \n",
    "\n",
    "Attentionの仕組みはやはりゼロから作るDeep Learning ❷ ―自然言語処理編が圧倒的にわかりやすかったです。  \n",
    "\n",
    "これからご紹介する実装例は、ゼロ作2のスクラッチによる実装をただPyTorchで真似ただけ(になってるはず)なので、本記事がわかりにくかったら、ゼロ作2を一読されることを強くおすすめします。  \n",
    "\n",
    "https://qiita.com/m__k/items/646044788c5f94eadc8d\n",
    "\n",
    "## 補足\n",
    "Attentionにもsoft Attention、hard Attentionなどいろいろあるかと思いますが、ここでいうAttentionはゼロから作るDeep Learning ❷ ―自然言語処理編で説明されている(softな)Attentionを指すことにします。\n",
    "\n",
    "# Attentionの仕組み\n",
    "## Seq2Seqの課題\n",
    "Seq2SeqはEncoderがインプットの系列の長さによらず、固定長ベクトルに変換してしまうので、長い系列などは特徴が捉えきれない、という課題があります。  \n",
    "Attentionは、この課題を解決すべく、Encoder側のインプットの系列の長さを考慮できる仕組みを用意します。  \n",
    "\n",
    "## 超ざっくり説明\n",
    "超ざっくりとAttentionの説明をすると  \n",
    "\n",
    "1. Encoder側の各隠れ層の値をすべてDecoder側の各層に渡す  \n",
    "1. Decoder側の各層において、Encoder側から渡された各隠れ層のベクトルのうち、最も注意すべきベクトルを選び出して特徴に加える  \n",
    "\n",
    "という操作をします。  \n",
    "1.において、Encoder側の隠れ層ベクトルの数は、Encoder側のインプットとなる系列の長さに依存するので、系列の長さを考慮した形になっている  \n",
    "2.において、選び出すという操作は微分できないが、各要素のどこに注意すべきかを$softmax$で確率的に重み付けした形で選ぶ操作を行います。  \n",
    "\n",
    "## もう少し詳細にAttentionの処理の流れを図を使って説明\n",
    "以下の図は簡単のために、Encoder側のインプットの系列がw1, w2, w3の3つのとき、Decoder側がw'1, w'2の2つのケースを扱っています。  \n",
    "\n",
    "①  \n",
    "Encoder側の各隠れ層の値をそれぞれ$h_{1}$,$h_{2}$, ⋯⋯, $h_{n}$としたとき、$hs$=[$h_{1}$, $h_{2}$,⋯, $h_{n}$] をDecoder側の各層に渡す。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./doc/image/4-1.png\" width=800\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "②  \n",
    "Decoder側の各隠れ層のベクトル(ここでは$d_{i}$とする)と、$h_{s}$の各ベクトル$h_{1}$,$h_{2}$,⋯との内積を計算する。  \n",
    "これはDecoder側の各ベクトルと$hs$の各ベクトルがどれだけ似ているかを計算していることを意味する。（内積は$(⋅,⋅)$で表記してます。）\n",
    "\n",
    "<center><img src=\"./doc/image/4-2.png\" width=\"800\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③  \n",
    "②で計算した内積を$softmax$で確率表現に変換する（これをattention weightとか言ったりする）\n",
    "<center><img src=\"./doc/image/4-3.png\" width=\"800\" align=\"center\"/></center>\n",
    "attention weightの1行目は、Encoderの1番目のLSTM/GRUが出力した隠れ状態に対するattention、<br/>\n",
    "2行目は、Encoderの2番目のLSTM/GRUが出力した隠れ状態に対するattention、<br/>\n",
    "：<br/>\n",
    "$attention\\ weight$ = $[[1番目の単語のweight]]$<br/>\n",
    "　　　　　　　　　　$[2番目の単語のweight]$<br/>\n",
    "　　　　　　　　　　$[3番目の単語のweight]$<br/>\n",
    "　　　　　　　　　　：<br/>\n",
    "　　　　　　　　　　$[N番目の単語のweight]]$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④  \n",
    "$hs$の各要素をattention weightで重み付けして全部足しあわせて1本のベクトルとする（これをコンテキストベクトルとかいったりする）\n",
    "<center><img src=\"./doc/image/4-4.png\" width=\"600\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⑤  \n",
    "コンテキストベクトルと$d_{i}$を結合して、1本のベクトルにする\n",
    "<center><img src=\"./doc/image/4-5.png\" width=\"800\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実装\n",
    "- 上で説明した1~5の処理をDecoder側に加えれば完成です。ゼロ作2と同様に日付フォーマットの変換問題を扱います。（attention weightを可視化したとき確からしさが確認しやすいため）\n",
    "- 以下はGoogle Colab上で実装しています。\n",
    "- 前回で説明したSeq2Seqの実装にAttentionの処理を加える形で説明するので、大部分は前回のソースを使いまわしています。前回のソースコードもぜひご参照ください。\n",
    "  - PyTorchでSeq2Seqを実装してみた\n",
    "\n",
    "## 問題設定\n",
    "以下のような様々な日付の書き方をYYYY-MM-DDのフォーマットに変換するタスクをAttention seq2seqで解かせてみます。\n",
    "\n",
    "<center><img src=\"./doc/image/4-9.png\" width=\"300\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import linecache\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.utils import shuffle \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備\n",
    "https://github.com/oreilly-japan/deep-learning-from-scratch-2/raw/master/dataset/date.txt\n",
    "を入手する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date.txt exists.\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"date.txt\"\n",
    "if not os.path.exists(file_path):\n",
    "    !wget https://github.com/oreilly-japan/deep-learning-from-scratch-2/raw/master/dataset/date.txt\n",
    "else:\n",
    "    print(\"date.txt exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['september 27, 1994           ', 'August 19, 2003              ', '2/10/93                      ', '10/31/90                     ', 'TUESDAY, SEPTEMBER 25, 1984  ']\n",
      "['_1994-09-27', '_2003-08-19', '_1993-02-10', '_1990-10-31', '_1984-09-25']\n"
     ]
    }
   ],
   "source": [
    "input_date = [] # 変換前の日付データ\n",
    "output_date = [] # 変換後の日付データ\n",
    "\n",
    "# date.txtを1行ずつ読み込んで変換前と変換後に分割して、inputとoutputで分ける\n",
    "with open(file_path, \"r\") as f:\n",
    "  date_list = f.readlines()\n",
    "  for date in date_list:\n",
    "    date = date[:-1]\n",
    "    input_date.append(date.split(\"_\")[0])\n",
    "    output_date.append(\"_\" + date.split(\"_\")[1])\n",
    "\n",
    "print(input_date[:5])\n",
    "print(output_date[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_len:29\n",
      "output_len:11\n"
     ]
    }
   ],
   "source": [
    "# inputとoutputの系列の長さを取得\n",
    "# すべて長さが同じなので、0番目の要素でlenを取ってます\n",
    "input_len = len(input_date[0]) # 29\n",
    "output_len = len(output_date[0]) # 10\n",
    "\n",
    "print(f\"input_len:{input_len}\")\n",
    "print(f\"output_len:{output_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 0, 'e': 1, 'p': 2, 't': 3, 'm': 4, 'b': 5, 'r': 6, ' ': 7, '2': 8, '7': 9, ',': 10, '1': 11, '9': 12, '4': 13, '_': 14, '-': 15, '0': 16, 'A': 17, 'u': 18, 'g': 19, '3': 20, '8': 21, '/': 22, 'T': 23, 'U': 24, 'E': 25, 'S': 26, 'D': 27, 'Y': 28, 'P': 29, 'M': 30, 'B': 31, 'R': 32, '5': 33, 'J': 34, 'N': 35, '6': 36, 'a': 37, 'i': 38, 'l': 39, 'O': 40, 'c': 41, 'o': 42, 'G': 43, 'F': 44, 'y': 45, 'n': 46, 'C': 47, 'W': 48, 'd': 49, 'I': 50, 'L': 51, 'j': 52, 'H': 53, 'v': 54, 'h': 55, 'V': 56, 'f': 57, 'w': 58}\n"
     ]
    }
   ],
   "source": [
    "# date.txtで登場するすべての文字にIDを割り当てる\n",
    "char2id = {}\n",
    "for input_chars, output_chars in zip(input_date, output_date):\n",
    "  for c in input_chars:\n",
    "    if not c in char2id:\n",
    "      char2id[c] = len(char2id)\n",
    "  for c in output_chars:\n",
    "    if not c in char2id:\n",
    "      char2id[c] = len(char2id)\n",
    "\n",
    "print(char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [] # ID化された変換前日付データ\n",
    "output_data = [] # ID化された変換後日付データ\n",
    "for input_chars, output_chars in zip(input_date, output_date):\n",
    "  input_data.append([char2id[c] for c in input_chars])\n",
    "  output_data.append([char2id[c] for c in output_chars])\n",
    "\n",
    "# 7:3でtrainとtestに分ける\n",
    "train_x, test_x, train_y, test_y = train_test_split(input_data, output_data, train_size= 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをバッチ化するための関数を定義\n",
    "def train2batch(input_data, output_data, batch_size=100):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    input_shuffle, output_shuffle = shuffle(input_data, output_data)\n",
    "    for i in range(0, len(input_data), batch_size):\n",
    "      input_batch.append(input_shuffle[i:i+batch_size])\n",
    "      output_batch.append(output_shuffle[i:i+batch_size])\n",
    "    return input_batch, output_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "- Encoder側はほとんど前回実装したseq2seqから変わりません。\n",
    "- 少しでも楽したいので、LSTMはGRUに変えてます。\n",
    "- GRUの各隠れ層の値はDecoder側でAttentionされるために使うので、GRUの第１戻り値($hs$)も受け取ってます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 諸々のパラメータなど\n",
    "embedding_dim = 200\n",
    "hidden_dim = 128\n",
    "BATCH_NUM = 100\n",
    "vocab_size = len(char2id)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoderクラス\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=char2id[\" \"])\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        embedding = self.word_embeddings(sequence)\n",
    "        # hsが各系列のGRUの隠れ層のベクトル\n",
    "        # Attentionされる要素\n",
    "        hs, h = self.gru(embedding)\n",
    "        return hs, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- こっちもEncoder側と同様に前回と比べてLSTMをGRUに変えてます。\n",
    "- 紙とかに各層のテンソルのどの軸がなんの意味なのかを書きながら実装すると頭が整理できます。\n",
    "- 少しでも理解の助けになるためにAttention層の各テンソルのサイズも記載してみました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_x\n",
      "torch.Size([4, 3, 2])\n",
      "tensor([[[ 0.5443, -0.4202],\n",
      "         [ 0.6082, -1.1414],\n",
      "         [-0.0353, -0.1106]],\n",
      "\n",
      "        [[-2.4696,  1.5686],\n",
      "         [-0.4551,  1.1029],\n",
      "         [ 2.2562, -0.6050]],\n",
      "\n",
      "        [[-1.7866, -0.1211],\n",
      "         [ 0.7173, -0.3112],\n",
      "         [ 0.4281,  0.0514]],\n",
      "\n",
      "        [[-0.1109, -0.5966],\n",
      "         [-1.0941,  0.0713],\n",
      "         [ 0.5763, -0.7629]]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([3, 4, 2])\n",
      "tensor([[[ 0.5443, -0.4202],\n",
      "         [-2.4696,  1.5686],\n",
      "         [-1.7866, -0.1211],\n",
      "         [-0.1109, -0.5966]],\n",
      "\n",
      "        [[ 0.6082, -1.1414],\n",
      "         [-0.4551,  1.1029],\n",
      "         [ 0.7173, -0.3112],\n",
      "         [-1.0941,  0.0713]],\n",
      "\n",
      "        [[-0.0353, -0.1106],\n",
      "         [ 2.2562, -0.6050],\n",
      "         [ 0.4281,  0.0514],\n",
      "         [ 0.5763, -0.7629]]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 0.5443,  0.6082, -0.0353],\n",
      "         [-0.4202, -1.1414, -0.1106]],\n",
      "\n",
      "        [[-2.4696, -0.4551,  2.2562],\n",
      "         [ 1.5686,  1.1029, -0.6050]],\n",
      "\n",
      "        [[-1.7866,  0.7173,  0.4281],\n",
      "         [-0.1211, -0.3112,  0.0514]],\n",
      "\n",
      "        [[-0.1109, -1.0941,  0.5763],\n",
      "         [-0.5966,  0.0713, -0.7629]]])\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_x = torch.randn(4, 3, 2)\n",
    "print(\"test_x\")\n",
    "print(test_x.size())\n",
    "print(test_x)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "test_x2 = torch.transpose(test_x, 0, 1)\n",
    "print(test_x2.size())\n",
    "print(test_x2)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "test_x3 = torch.transpose(test_x, 1, 2)\n",
    "print(test_x3.size())\n",
    "print(test_x3)\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Decoderクラス\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=char2id[\" \"])\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # hidden_dim*2としているのは、各系列のGRUの隠れ層とAttention層で計算したコンテキストベクトルをtorch.catでつなぎ合わせることで長さが２倍になるため\n",
    "        self.hidden2linear = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "        # 列方向を確率変換したいのでdim=1\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, sequence, hs, h):\n",
    "        embedding = self.word_embeddings(sequence)\n",
    "        output, state = self.gru(embedding, h)\n",
    "\n",
    "        # Attention層\n",
    "        # hs.size() = ([100, 29, 128])\n",
    "        # output.size() = ([100, 10, 128])\n",
    "\n",
    "        # bmmを使ってEncoder側の出力(hs)とDecoder側の出力(output)をbatchごとまとめて行列計算するために、Decoder側のoutputをbatchを固定して転置行列を取る\n",
    "        # ※torch.transpose(TENSOR, A, B)\n",
    "        # 　→ テンソルTENSORのA次元目とB次元目を転置する。\n",
    "        t_output = torch.transpose(output, 1, 2) # t_output.size() = ([100, 128, 10])\n",
    "\n",
    "        # bmmで、Encoder側の出力(hs)とDecoder側の出力(output)をバッチも考慮してまとめて行列計算\n",
    "        # つまり[100, 29, 128]hsと[100, 128, 10]outputの行列積の計算をおこなう。\n",
    "        s = torch.bmm(hs, t_output) # s.size() = ([100, 29, 10])\n",
    "\n",
    "        # 列方向(dim=1)でsoftmaxをとって確率表現に変換\n",
    "        # この値を後のAttentionの可視化などにも使うため、returnで返しておく\n",
    "        attention_weight = self.softmax(s) # attention_weight.size() = ([100, 29, 10])\n",
    "\n",
    "        # コンテキストベクトルをまとめるために入れ物を用意\n",
    "        c = torch.zeros(self.batch_size, 1, self.hidden_dim, device=device) # c.size() = ([100, 1, 128])\n",
    "\n",
    "        # 各DecoderのGRU層に対するコンテキストベクトルをまとめて計算する方法がわからなかったので、\n",
    "        # 各層（Decoder側のGRU層は生成文字列が10文字なので10個ある）におけるattention weightを取り出してforループ内でコンテキストベクトルを１つずつ作成する\n",
    "        # バッチ方向はまとめて計算できたのでバッチはそのまま\n",
    "        for i in range(attention_weight.size()[2]): # 10回ループ\n",
    "\n",
    "          # attention_weight[:,:,i].size() = ([100, 29])\n",
    "          # i番目のGRU層に対するattention weightを取り出すが、テンソルのサイズをhsと揃えるためにunsqueezeする\n",
    "          unsq_weight = attention_weight[:,:,i].unsqueeze(2) # unsq_weight.size() = ([100, 29, 1])\n",
    "\n",
    "          # hsの各ベクトルをattention weightで重み付けする\n",
    "          weighted_hs = hs * unsq_weight # weighted_hs.size() = ([100, 29, 128])\n",
    "\n",
    "          # attention weightで重み付けされた各hsのベクトルをすべて足し合わせてコンテキストベクトルを作成\n",
    "          weight_sum = torch.sum(weighted_hs, axis=1).unsqueeze(1) # weight_sum.size() = ([100, 1, 128])\n",
    "\n",
    "          c = torch.cat([c, weight_sum], dim=1) # c.size() = ([100, i, 128])\n",
    "\n",
    "        # 箱として用意したzero要素が残っているのでスライスして削除\n",
    "        c = c[:,1:,:]\n",
    "\n",
    "        output = torch.cat([output, c], dim=2) # output.size() = ([100, 10, 256])\n",
    "        output = self.hidden2linear(output)\n",
    "        return output, state, attention_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル宣言、損失関数、最適化\n",
    "前回と特に変更なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "attn_decoder = AttentionDecoder(vocab_size, embedding_dim, hidden_dim, BATCH_NUM).to(device)\n",
    "\n",
    "# 損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "attn_decoder_optimizer = optim.Adam(attn_decoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "- Encoderのアウトプットである${hs}$を忘れずにAttention Decoderに渡せばOK\n",
    "- EncoderもDecoderもインプットとアウトプットに変更がないので、ほとんど前回のSeq2Seqのときと同じでOK\n",
    "- ものすごい勢いでlossが減っていきます\n",
    "- 以下ではlossの下限を0.1に設定してますが、16epoch目にしてもう到達してしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ...\n",
      "Epoch 1: 1491.27\n",
      "Epoch 2: 95.86\n",
      "Epoch 3: 58.69\n",
      "Epoch 4: 28.38\n",
      "Epoch 5: 21.89\n",
      "Epoch 6: 19.97\n",
      "Epoch 7: 26.15\n",
      "Epoch 8: 3.63\n",
      "Epoch 9: 1.26\n",
      "Epoch 10: 0.78\n",
      "Epoch 11: 0.54\n",
      "Epoch 12: 0.40\n",
      "Epoch 13: 0.30\n",
      "Epoch 14: 0.24\n",
      "Epoch 15: 0.19\n",
      "Epoch 16: 0.15\n",
      "Epoch 17: 0.12\n",
      "Epoch 18: 0.10\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "BATCH_NUM=100\n",
    "EPOCH_NUM = 100\n",
    "\n",
    "all_losses = []\n",
    "print(\"training ...\")\n",
    "for epoch in range(1, EPOCH_NUM+1):\n",
    "    epoch_loss = 0\n",
    "    # データをミニバッチに分ける\n",
    "    input_batch, output_batch = train2batch(train_x, train_y, batch_size=BATCH_NUM)\n",
    "    for i in range(len(input_batch)):\n",
    "\n",
    "        # 勾配の初期化\n",
    "        encoder_optimizer.zero_grad()\n",
    "        attn_decoder_optimizer.zero_grad()\n",
    "\n",
    "        # データをテンソルに変換\n",
    "        input_tensor = torch.tensor(input_batch[i], device=device)\n",
    "        output_tensor = torch.tensor(output_batch[i], device=device)\n",
    "\n",
    "        # Encoderの順伝搬\n",
    "        hs, h = encoder(input_tensor)\n",
    "\n",
    "        # Attention Decoderのインプット\n",
    "        source = output_tensor[:, :-1]\n",
    "\n",
    "        # Attention Decoderの正解データ\n",
    "        target = output_tensor[:, 1:]\n",
    "\n",
    "        loss = 0\n",
    "        decoder_output, _, attention_weight= attn_decoder(source, hs, h)\n",
    "        for j in range(decoder_output.size()[1]):\n",
    "            loss += criterion(decoder_output[:, j, :], target[:, j])\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # 誤差逆伝播\n",
    "        loss.backward()\n",
    "\n",
    "        # パラメータ更新\n",
    "        encoder_optimizer.step()\n",
    "        attn_decoder_optimizer.step()\n",
    "\n",
    "    # 損失を表示\n",
    "    print(\"Epoch %d: %.2f\" % (epoch, epoch_loss))\n",
    "    all_losses.append(epoch_loss)\n",
    "    if epoch_loss < 0.1: break\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f932c3e4760>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測\n",
    "- 前回のSeq2Seqのときの予測とほぼ同じ方法で予測させてます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoderのアウトプットのテンソルから要素が最大のインデックスを返す。つまり生成文字を意味する\n",
    "def get_max_index(decoder_output):\n",
    "  results = []\n",
    "  for h in decoder_output:\n",
    "    results.append(torch.argmax(h))\n",
    "  return torch.tensor(results, device=device).view(BATCH_NUM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用データ\n",
    "test_input_batch, test_output_batch = train2batch(test_x, test_y)\n",
    "input_tensor = torch.tensor(test_input_batch, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []\n",
    "for i in range(len(test_input_batch)):\n",
    "  with torch.no_grad():\n",
    "    hs, encoder_state = encoder(input_tensor[i])\n",
    "\n",
    "    # Decoderにはまず文字列生成開始を表す\"_\"をインプットにするので、\"_\"のtensorをバッチサイズ分作成\n",
    "    start_char_batch = [[char2id[\"_\"]] for _ in range(BATCH_NUM)]\n",
    "    decoder_input_tensor = torch.tensor(start_char_batch, device=device)\n",
    "\n",
    "    decoder_hidden = encoder_state\n",
    "    batch_tmp = torch.zeros(100,1, dtype=torch.long, device=device)\n",
    "    for _ in range(output_len - 1):\n",
    "      decoder_output, decoder_hidden, _ = attn_decoder(decoder_input_tensor, hs, decoder_hidden)\n",
    "      # 予測文字を取得しつつ、そのまま次のdecoderのインプットとなる\n",
    "      decoder_input_tensor = get_max_index(decoder_output.squeeze())\n",
    "      batch_tmp = torch.cat([batch_tmp, decoder_input_tensor], dim=1)\n",
    "    predicts.append(batch_tmp[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果を見る際にIDのままだと可読性が悪いので、もとの文字列に復元するためのID→文字列に変換する辞書を定義\n",
    "id2char = {}\n",
    "for k, v in char2id.items():\n",
    "  id2char[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>answer</th>\n",
       "      <th>predict</th>\n",
       "      <th>judge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/98</td>\n",
       "      <td>1998-01-22</td>\n",
       "      <td>1998-01-22</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>December 10, 1986</td>\n",
       "      <td>1986-12-10</td>\n",
       "      <td>1986-12-10</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thursday, june 4, 2015</td>\n",
       "      <td>2015-06-04</td>\n",
       "      <td>2015-06-04</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JANUARY 16, 1974</td>\n",
       "      <td>1974-01-16</td>\n",
       "      <td>1974-01-16</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/21/81</td>\n",
       "      <td>1981-06-21</td>\n",
       "      <td>1981-06-21</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           input      answer     predict judge\n",
       "0  1/22/98                        1998-01-22  1998-01-22     O\n",
       "1  December 10, 1986              1986-12-10  1986-12-10     O\n",
       "2  thursday, june 4, 2015         2015-06-04  2015-06-04     O\n",
       "3  JANUARY 16, 1974               1974-01-16  1974-01-16     O\n",
       "4  6/21/81                        1981-06-21  1981-06-21     O"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = []\n",
    "for i in range(len(test_input_batch)):\n",
    "  batch_input = test_input_batch[i]\n",
    "  batch_output = test_output_batch[i]\n",
    "  batch_predict = predicts[i]\n",
    "  for inp, output, predict in zip(batch_input, batch_output, batch_predict):\n",
    "    x = [id2char[idx] for idx in inp]\n",
    "    y = [id2char[idx] for idx in output[1:]]\n",
    "    p = [id2char[idx.item()] for idx in predict]\n",
    "\n",
    "    x_str = \"\".join(x)\n",
    "    y_str = \"\".join(y)\n",
    "    p_str = \"\".join(p)\n",
    "\n",
    "    judge = \"O\" if y_str == p_str else \"X\"\n",
    "    row.append([x_str, y_str, p_str, judge])\n",
    "predict_df = pd.DataFrame(row, columns=[\"input\", \"answer\", \"predict\", \"judge\"])\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正解率\n",
    "- 今回たまたま100%ではなかったですが、だいたい100%の正答率になると思います。\n",
    "- 本タスクを間違えるときはだいたい以下のようなスラッシュ区切りの日付フォーマットが多いように感じます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>answer</th>\n",
       "      <th>predict</th>\n",
       "      <th>judge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [input, answer, predict, judge]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predict_df.query('judge == \"O\"')) / len(predict_df))\n",
    "\n",
    "predict_df.query('judge == \"X\"').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention weight 可視化\n",
    "- Attentionの醍醐味の1つであるattention weightの可視化をしてみます。\n",
    "- attention weightを見ることで学習の確からしさを確認することができます。\n",
    "- attention weightの可視化にはよくheatmapが使われるので、seabornのheatmapで可視化してます。\n",
    "- 7:3に分けた3のほうのテストデータをバッチに分けたうちの最初のミニバッチを流しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, output_batch = train2batch(test_x, test_y, batch_size=BATCH_NUM)\n",
    "input_minibatch, output_minibatch = input_batch[0], output_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # データをテンソルに変換\n",
    "  input_tensor = torch.tensor(input_minibatch, device=device)\n",
    "  output_tensor = torch.tensor(output_minibatch, device=device)\n",
    "  hs, h = encoder(input_tensor)\n",
    "  source = output_tensor[:, :-1]\n",
    "  decoder_output, _, attention_weight= attn_decoder(source, hs, h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "  with torch.no_grad():\n",
    "    df = pd.DataFrame(data=torch.transpose(attention_weight[i], 0, 1).cpu().numpy(), \n",
    "                      columns=[id2char[idx.item()] for idx in input_tensor[i]], \n",
    "                      index=[id2char[idx.item()] for idx in output_tensor[i][1:]])\n",
    "    plt.figure(figsize=(12, 8)) \n",
    "    sns.heatmap(df, xticklabels = 1, yticklabels = 1, square=True, linewidths=.3,cbar_kws = dict(use_gridspec=False,location=\"top\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化をいくつか紹介\n",
    "<center><img src=\"./doc/image/4-6.png\" width=\"800\" align=\"center\"/></center>\n",
    "\n",
    "少々見づらくて恐縮ですが、上図の下の文字「Tuesday, March 27, 2012」が変換前の文字列（Encoderのインプット）で、左の縦に並んでいる「2012-03-27」が生成文字です。  \n",
    "このheatmapの見方ですが、Decoderの生成文字を１文字ずつ見たとき、左に並んでいるボックスの色が一番明るいところの文字に一番attentionして生成された文字ですよ、という意味になると思います。（違ってたらご指摘ください...）  \n",
    "(もちろん左方向にボックスの値をすべて足せば1になりますね。)  \n",
    "\n",
    "上図の例だと、以下のことがわかるのではないかと思います。  \n",
    "\n",
    "- 全体的にYYYYを生成するなら年の部分、MMを生成するなら月の部分に注目していることが伺えます。\n",
    "- 今回のタスクはYYYY-MM-DDへの変換、つまり曜日は変換されないので、「Tuesday」にはどの生成文字も注目していない\n",
    "- 「March」の「a」の部分を「0」がattentionしてます。「May」なら「05」、「March」なら「04」ですが、「Ma」と文字が並べば「0」の生成が確定しており、その後「rch」と文字が並んでいるので、最後の「h」に3が注目してるって感じ？\n",
    "\n",
    "※今回は生成されるべき正解の文字を表示しちゃってます。今回は正答率がほぼ100%なので、同じかと思いますが、ちゃんとやるならDecoderが生成した文字を１文字ずつ集計してattention weightを作成したほうが良いんだろうなぁと思います。手抜きで申し訳ございません...\n",
    "\n",
    "他にもこんな感じでAttentionされてます↓\n",
    "\n",
    "<center><img src=\"./doc/image/4-7.png\" width=\"800\" align=\"center\"/></center>\n",
    "<center><img src=\"./doc/image/4-8.png\" width=\"800\" align=\"center\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(pytorch_lstm)",
   "language": "python",
   "name": "pytorch_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
